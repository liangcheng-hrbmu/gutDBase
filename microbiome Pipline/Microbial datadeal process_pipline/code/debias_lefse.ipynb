{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f631fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "host = 'human'\n",
    "host_short = 'hum'\n",
    "taxonomy = 'phylum'\n",
    "metadata = pd.read_csv(\n",
    "    Rf\"D:\\Project\\gutDBase\\metadata\\{host_short}_pie.csv\", dtype=str)\n",
    "target_seq_type = 'Expression profiling by high throughput sequencing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f98e0",
   "metadata": {},
   "source": [
    "Expression profiling by high throughput sequencing\n",
    "\n",
    "Expression profiling by array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gse_list = metadata[metadata['info'] == 'metaclass']['accession'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c84e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_type_list = metadata[metadata['info'] == 'metaclass']['value'].unique()\n",
    "disease_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_gse_list = glob.glob(\n",
    "    Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gse_dict = {}\n",
    "for gse in all_gse_list:\n",
    "    record = metadata[(metadata['info'] == 'metaclass')\n",
    "                      & (metadata['accession'] == gse)]\n",
    "    disease_type = record['value'].unique().tolist()\n",
    "    disease_type.remove('normal')\n",
    "    count = record.shape[0]\n",
    "    old_dict = disease_gse_dict.get(list(disease_type)[0], {})\n",
    "    old_dict[gse] = count\n",
    "    new_dict = old_dict\n",
    "    disease_gse_dict[list(disease_type)[0]] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease, dict_list in disease_gse_dict.items():\n",
    "    for gse, ref_count in dict_list.items():\n",
    "        summary_file = os.path.join(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\")\n",
    "        if os.path.exists(summary_file):\n",
    "            df = pd.read_excel(summary_file, index_col=0,\n",
    "                               sheet_name='metaData')\n",
    "            true_count = df.shape[0]\n",
    "            if true_count == ref_count:\n",
    "                print(f\"{gse} is correct\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"{gse} has {ref_count} references, but {true_count} in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_type = pd.read_csv(R\"D:\\Project\\gutDBase\\metadata\\seq_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_cRNA = seq_type[seq_type['Study type'].isin(\n",
    "    [target_seq_type]) & (seq_type['Species'] == host_short)]['Accession'].tolist()\n",
    "gse_cRNA = list(set(gse_cRNA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_cRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40373a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_select_gse_dict = {}\n",
    "for disease, dict_list in disease_gse_dict.items():\n",
    "    select_gse = []\n",
    "    for gse, ref_count in dict_list.items():\n",
    "        summary_file = os.path.join(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\")\n",
    "        if os.path.exists(summary_file):\n",
    "            abundance = pd.read_excel(\n",
    "                summary_file, index_col=0, sheet_name=taxonomy)\n",
    "            meta_data = pd.read_excel(\n",
    "                summary_file, index_col=0, sheet_name='metaData')\n",
    "            if abundance.shape[1] != meta_data.shape[0]:\n",
    "                print(f\"{gse} abundance and meta data not match\")\n",
    "            else:\n",
    "                if gse in gse_cRNA:\n",
    "                    select_gse.append(gse)\n",
    "                    print(f\"{gse} selected\")\n",
    "                else:\n",
    "                    print(f\"{gse} not selected due to not target seq type\")\n",
    "    disease_select_gse_dict[disease] = select_gse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_select_gse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d871f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abundance_feature_union_set(selected_gse_list: list[str]):\n",
    "    abundance_t_dict: dict[str, pd.DataFrame] = {}\n",
    "    all_features = set()\n",
    "    for gse in selected_gse_list:\n",
    "        abundance_t = pd.read_excel(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\", index_col=0, sheet_name=taxonomy).T\n",
    "        # abundance_t.columns = abundance_t.columns.str.replace(\n",
    "        #     R\"\\.\\d+$\", \"\", regex=True)\n",
    "        # abundance_t = abundance_t.groupby(abundance_t.columns, axis=1).mean()\n",
    "        abundance_t_dict[gse] = abundance_t\n",
    "        all_features.update(abundance_t.columns)\n",
    "\n",
    "    all_features = sorted(all_features, reverse=True)\n",
    "\n",
    "    new_abundance_t_dict = {}\n",
    "    for gse in selected_gse_list:\n",
    "        new_abundance_t = abundance_t_dict[gse].copy()\n",
    "        new_abundance_t = new_abundance_t.reindex(\n",
    "            columns=all_features, fill_value=0)\n",
    "        new_abundance_t_dict[gse] = new_abundance_t\n",
    "\n",
    "    return new_abundance_t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(selected_gse_list: list[str]):\n",
    "    label_dict: dict[str, pd.Series] = {}\n",
    "    for gse in selected_gse_list:\n",
    "        records = metadata[(metadata['info'] == 'metaclass')\n",
    "                           & (metadata['accession'] == gse)]\n",
    "        y = records[['sample', 'value']]\n",
    "        y = y.set_index('sample')['value'].map(\n",
    "            lambda x: 0 if x == 'normal' else 1)\n",
    "        label_dict[gse] = y\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb61248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_gse_x_y_dict(abundance_t_dict: dict[str, pd.DataFrame], label_dict: dict[str, pd.Series], selected_gse_list: list[str]):\n",
    "    gse2x_y_dict = {}\n",
    "    for gse in selected_gse_list:\n",
    "        x = abundance_t_dict[gse]\n",
    "        y = label_dict[gse]\n",
    "        shared_index = x.index.intersection(y.index)\n",
    "        x = x.loc[shared_index]\n",
    "        y = y.loc[shared_index]\n",
    "        # metadata deduplication\n",
    "        y = y[~y.index.duplicated(keep=\"first\")]\n",
    "        gse2x_y_dict[gse] = {\"x\": x, \"y\": y}\n",
    "    return gse2x_y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bab4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2_x_y_dict: dict[str, dict[str, pd.DataFrame | pd.Series]] = {}\n",
    "for disease, gse_list in disease_select_gse_dict.items():\n",
    "    if len(gse_list) < 2:\n",
    "        print(f\"{disease} insufficient quantity of fewer than 2, skipping.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{disease}: {len(gse_list)}\")\n",
    "        gse_abundance_t_dict = abundance_feature_union_set(gse_list)\n",
    "        gse_label_dict = extract_label(gse_list)\n",
    "        x_y_dict = composite_gse_x_y_dict(\n",
    "            gse_abundance_t_dict, gse_label_dict, gse_list)\n",
    "        gse2_x_y_dict[disease] = x_y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease, gse_x_y in gse2_x_y_dict.items():\n",
    "    for gse, x_y in gse_x_y.items():\n",
    "        print(f\"{disease}\\t{gse}\\t{x_y['x'].shape}\\t{x_y['y'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gse, x_y in gse2_x_y_dict['IBD'].items():\n",
    "    print(gse, x_y['x'].shape, x_y['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gse, x_y in gse2_x_y_dict['IBD'].items():\n",
    "    print(gse, x_y['x'].isnull().values.any(), x_y['y'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a55472",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2_x_y_dict['IBD']['GSE166925']['x'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2_x_y_dict['IBD']['GSE166925']['y'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from debiasm import DebiasMClassifier\n",
    "\n",
    "\n",
    "def merge_and_add_batch_labels(gse_x_y_dict: dict[str, dict[str, pd.DataFrame | pd.Series]]):\n",
    "    \"\"\"\n",
    "    Merge multiple GSE datasets under a disease, with batch numbers in the first column.\n",
    "    Return X_all, y_all, batch_1abels\n",
    "    \"\"\"\n",
    "    X_list, y_list, batch_list = [], [], []\n",
    "    feature_names: list[str] = []\n",
    "    sample_names: list[str] = []\n",
    "    for batch_id, (gse, x_y) in enumerate(gse_x_y_dict.items()):\n",
    "        feature_names = x_y[\"x\"].columns.tolist()\n",
    "        sample_names.extend(x_y[\"x\"].index.tolist())\n",
    "        x = x_y[\"x\"].values\n",
    "        y = x_y[\"y\"].values\n",
    "\n",
    "        # Add batch number column before X\n",
    "        batch_col = np.full((x.shape[0], 1), batch_id)\n",
    "        x_with_batch = np.hstack((batch_col, x))\n",
    "\n",
    "        X_list.append(x_with_batch)\n",
    "        y_list.append(y)\n",
    "        batch_list.extend([gse]*x.shape[0])\n",
    "\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "\n",
    "    return X_all, y_all, batch_list, feature_names, sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_validation(X_all: np.ndarray, y_all: np.ndarray):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X_all: numpy array, shape (n_samples, n_features+1)，first column is batch_id\n",
    "        y_all: numpy array, shape (n_samples,)\n",
    "    output:\n",
    "        X_train, X_val, y_train, y_val\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that y_all is a numpy array\n",
    "    if not isinstance(y_all, np.ndarray):\n",
    "        y_all = y_all.to_numpy()\n",
    "\n",
    "    # Check if the sample size is aligned\n",
    "    assert X_all.shape[0] == y_all.shape[0], f\"Sample size mismatch: X={X_all.shape[0]}, y={y_all.shape[0]}\"\n",
    "\n",
    "    # Select the maximum batch_id as the validation set\n",
    "    batch_ids = X_all[:, 0].astype(int)\n",
    "    unique, counts = np.unique(batch_ids, return_counts=True)\n",
    "    most_common_batch = unique[counts.argmax()]   # The batch_id with the most occurrences\n",
    "    val_inds = (batch_ids == most_common_batch)\n",
    "\n",
    "    # split the data into training and validation sets\n",
    "    X_train, X_val = X_all[~val_inds], X_all[val_inds]\n",
    "    y_train, y_val = y_all[~val_inds], y_all[val_inds]\n",
    "\n",
    "    print(f\"total: {len(y_all)} | training set: {len(y_train)} | validation set: {len(y_val)} | unique batch_ids: {len(np.unique(batch_ids))}\")\n",
    "\n",
    "    # check if there are any NaN\n",
    "    print(\"X_train has NaN:\", np.isnan(X_train).any())\n",
    "    print(\"X_val has NaN:\", np.isnan(X_val).any())\n",
    "    print(\"y_train has NaN:\", pd.isnull(y_train).any())\n",
    "    print(\"y_val has NaN:\", pd.isnull(y_val).any())\n",
    "\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668dd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias_batch_analysis(X_train, X_val, y_train, y_val, X_all):\n",
    "\n",
    "    dmc = DebiasMClassifier(x_val=X_val)\n",
    "    dmc.fit(X_train, y_train)\n",
    "\n",
    "    X_debiassed = dmc.transform(X_all)\n",
    "    return X_debiassed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease2_debiased = {}\n",
    "\n",
    "for disease, gse_x_y in gse2_x_y_dict.items():\n",
    "    print(f\"Processing {disease}, with a total of {len (gse_x_y)} datasets\")\n",
    "    temp_gse, temp_x_y = next(iter(gse_x_y.items()))\n",
    "    # feature_names = temp_x_y['x'].columns.tolist()\n",
    "    # print(f\"There are {len (feature_name)} features in total\")\n",
    "    # sample_names = []\n",
    "    # for gse, x_y in gse_x_y.items():\n",
    "    #     gses = x_y['y'].index.tolist()\n",
    "    #     sample_names.extend(gses)\n",
    "    X_all, y_all, batch_labels, feature_names, sample_names = merge_and_add_batch_labels(gse_x_y)\n",
    "\n",
    "    print(\"has NaN:\", np.isnan(X_all).any())\n",
    "    print(\"NaN number:\", np.isnan(X_all).sum())\n",
    "\n",
    "    # If it is a DataFrame, you can check the specific location\n",
    "    if not isinstance(X_all, np.ndarray):\n",
    "        nan_locs = X_all.isnull().sum().sort_values(ascending=False)\n",
    "        print(\"The top 10 features with the most NaN:\")\n",
    "        print(nan_locs.head(10))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = split_training_validation(X_all, y_all)\n",
    "    X_debiassed = debias_batch_analysis(X_train, X_val, y_train, y_val, X_all)\n",
    "    X_debiassed = pd.DataFrame(\n",
    "        X_debiassed, columns=feature_names, index=sample_names)\n",
    "\n",
    "    sample_y_batch = pd.DataFrame(\n",
    "        {'y': y_all, 'batch': batch_labels}, index=sample_names)\n",
    "    sample_y_batch.index.name = 'Sample Name'\n",
    "\n",
    "    disease2_debiased[disease] = {\n",
    "        \"X_raw\": X_all,\n",
    "        \"X_debiassed\": X_debiassed,\n",
    "        \"sample_y_batch\": sample_y_batch\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e624a40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2951fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def get_host_microbiome_associate_genes(disease: str, cor_p_filter=0.05):\n",
    "    mat = disease2_debiased[disease]['X_debiassed'].copy()\n",
    "    mat_meta = disease2_debiased[disease]['sample_y_batch']\n",
    "    mat_meta.replace({'y': {1: disease, 0: 'normal'}}, inplace=True)\n",
    "    mat_meta['Sample Name'] = mat_meta.index\n",
    "    lefse_result = pd.read_csv(\n",
    "        Rf\"D:\\Project\\gutDBase\\debias\\{host}\\{disease}\\lefse.LDA.xls\", sep='\\t', header=None)\n",
    "    lefse_result.columns = [\n",
    "        'Taxonomy', 'mean abundance(log10)', 'the class with the highest mean', 'LDA score', 'p value']\n",
    "    selected_lefse_result = lefse_result[lefse_result['LDA score'] > 2].copy()\n",
    "    selected_lefse_result['Taxonomy'] = selected_lefse_result['Taxonomy'].str.replace(\n",
    "        r'\\.(?=[kpcofgs]__)', '|', regex=True)\n",
    "    selected_taxonomy = selected_lefse_result['Taxonomy'].tolist()\n",
    "    selected_species = [tax for tax in selected_taxonomy if tax in mat.columns]\n",
    "    gene_exp = pd.read_csv(\n",
    "        Rf\"D:\\Project\\gutDBase\\debias\\{host}\\{disease}\\combat_data.txt\", sep=\"\\t\")\n",
    "    selected_sample = mat.index.intersection(gene_exp.columns)\n",
    "    gene_exp = gene_exp[selected_sample]\n",
    "\n",
    "    # Trim the taxonomy to the last level and merge the ones with the same name.\n",
    "    def extract_tax(tax: str):\n",
    "\n",
    "        for level in ['s__', 'g__', 'f__', 'o__', 'c__', 'p__', 'k__']:\n",
    "            if level in tax:\n",
    "                return level+tax.split(level)[-1]\n",
    "        return tax\n",
    "\n",
    "    species2genus = {sp: extract_tax(sp) for sp in selected_species}\n",
    "\n",
    "    # Keep the first fullname_taxa as a reference.\n",
    "    genus2fullname = {}\n",
    "    for sp in selected_species:\n",
    "        g = species2genus[sp]\n",
    "        if g not in genus2fullname:\n",
    "            genus2fullname[g] = sp\n",
    "\n",
    "    # Select the features and merge the columns of the same genus (sum them up)\n",
    "    micro_abu = mat[selected_species].copy()\n",
    "    micro_abu = micro_abu.groupby(species2genus, axis=1).sum().T\n",
    "\n",
    "    # 6. Pearson correlation significance mask\n",
    "    cor_result = []\n",
    "    for sp in micro_abu.index:\n",
    "        for gene in gene_exp.index:\n",
    "            corr, p = pearsonr(micro_abu.loc[sp], gene_exp.loc[gene])\n",
    "            cor_result.append(\n",
    "                [sp, gene, corr if p < cor_p_filter else 0, p])\n",
    "\n",
    "    df_cor = pd.DataFrame(cor_result, columns=[\n",
    "        'species', 'gene', 'correlation', 'p_value'])\n",
    "    df_cor['accession'] = fR\"all_{disease}_{target_seq_type}\"\n",
    "\n",
    "    # 7. Retain genes and microorganisms with non-zero relevance\n",
    "    pivot = df_cor.pivot(index='species', columns='gene',\n",
    "                         values='correlation').fillna(0)\n",
    "    species_keep = pivot[(pivot != 0).any(axis=1)].index\n",
    "    gene_keep = pivot.loc[species_keep].T[(\n",
    "        pivot.loc[species_keep].T != 0).any(axis=1)].index\n",
    "\n",
    "    df_final = df_cor[df_cor['species'].isin(\n",
    "        species_keep) & df_cor['gene'].isin(gene_keep)]\n",
    "    df_final = df_final[['species', 'gene',\n",
    "                         'correlation', 'accession']]\n",
    "    df_final['level'] = taxonomy\n",
    "    df_final.insert(0, 'id', range(len(df_final)))\n",
    "\n",
    "    # 8. Build LDA table\n",
    "    df_LDA = selected_lefse_result[['Taxonomy','the class with the highest mean', 'LDA score']].copy()\n",
    "    df_LDA['full_taxonomy'] = df_LDA['Taxonomy']\n",
    "    df_LDA['Taxonomy'] = df_LDA['Taxonomy'].apply(lambda tax: tax.split('|')[-1])\n",
    "    df_LDA['level'] = taxonomy\n",
    "    df_LDA['taxa'] = df_LDA['Taxonomy'].apply(lambda tax: tax.split('__',1)[-1])\n",
    "    df_LDA['accession'] = fR\"all_{disease}_{target_seq_type}\"\n",
    "    df_LDA.columns = ['species', 'group', 'ldascore','full_taxonomy','level','taxa','accession']\n",
    "    df_LDA.insert(0, 'id', range(len(df_LDA)))\n",
    "\n",
    "    return df_final, df_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_disease_cor_list: list[pd.DataFrame] = []\n",
    "debias_disease_LDA_list: list[pd.DataFrame] = []\n",
    "for disease, abu_data in disease2_debiased.items():\n",
    "    print(f\"{disease}...\")\n",
    "    cor_df, LDA_df = get_host_microbiome_associate_genes(disease)\n",
    "    debias_disease_cor_list.append(cor_df)\n",
    "    debias_disease_LDA_list.append(LDA_df)\n",
    "debias_disease_cor = pd.concat(debias_disease_cor_list)\n",
    "debias_disease_LDA = pd.concat(debias_disease_LDA_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e64441",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_disease_cor.columns = [\n",
    "    'id', 'cell_type1', 'cell_type2', 'correlation', 'accession','level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa58f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_disease_cor.to_csv(\n",
    "    Rf\"D:\\Project\\gutDBase\\debias\\{host}\\debias_disease_cor_{taxonomy}_{target_seq_type}.csv\", index=False)\n",
    "debias_disease_LDA.to_csv(\n",
    "    Rf\"D:\\Project\\gutDBase\\debias\\{host}\\debias_disease_cor_{taxonomy}_{target_seq_type}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
