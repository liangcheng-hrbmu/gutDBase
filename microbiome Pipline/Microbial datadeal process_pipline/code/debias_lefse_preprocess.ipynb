{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f631fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "host = 'mouse'\n",
    "host_short = 'mus'\n",
    "taxonomy = 'species'\n",
    "metadata = pd.read_csv(\n",
    "    Rf\"D:\\Project\\gutDBase\\metadata\\{host_short}_pie.csv\", dtype=str)\n",
    "target_seq_type = 'Expression profiling by high throughput sequencing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f98e0",
   "metadata": {},
   "source": [
    "Expression profiling by high throughput sequencing\n",
    "\n",
    "Expression profiling by array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gse_list = metadata[metadata['info'] == 'metaclass']['accession'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c84e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_type_list = metadata[metadata['info'] == 'metaclass']['value'].unique()\n",
    "disease_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_gse_list = glob.glob(\n",
    "    Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gse_dict = {}\n",
    "for gse in all_gse_list:\n",
    "    record = metadata[(metadata['info'] == 'metaclass')\n",
    "                      & (metadata['accession'] == gse)]\n",
    "    disease_type = record['value'].unique().tolist()\n",
    "    disease_type.remove('normal')\n",
    "    count = record.shape[0]\n",
    "    old_dict = disease_gse_dict.get(list(disease_type)[0], {})\n",
    "    old_dict[gse] = count\n",
    "    new_dict = old_dict\n",
    "    disease_gse_dict[list(disease_type)[0]] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease, dict_list in disease_gse_dict.items():\n",
    "    for gse, ref_count in dict_list.items():\n",
    "        summary_file = os.path.join(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\")\n",
    "        if os.path.exists(summary_file):\n",
    "            df = pd.read_excel(summary_file, index_col=0,\n",
    "                               sheet_name='metaData')\n",
    "            true_count = df.shape[0]\n",
    "            if true_count == ref_count:\n",
    "                print(f\"{gse} is correct\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"{gse} has {ref_count} references, but {true_count} in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_type = pd.read_csv(R\"D:\\Project\\gutDBase\\metadata\\seq_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_cRNA = seq_type[seq_type['Study type'].isin(\n",
    "    [target_seq_type]) & (seq_type['Species'] == host_short)]['Accession'].tolist()\n",
    "gse_cRNA = list(set(gse_cRNA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_cRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40373a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_select_gse_dict = {}\n",
    "for disease, dict_list in disease_gse_dict.items():\n",
    "    select_gse = []\n",
    "    for gse, ref_count in dict_list.items():\n",
    "        summary_file = os.path.join(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\")\n",
    "        if os.path.exists(summary_file):\n",
    "            abundance = pd.read_excel(\n",
    "                summary_file, index_col=0, sheet_name=taxonomy)\n",
    "            meta_data = pd.read_excel(\n",
    "                summary_file, index_col=0, sheet_name='metaData')\n",
    "            if abundance.shape[1] != meta_data.shape[0]:\n",
    "                print(f\"{gse} abundance and meta data not match\")\n",
    "            else:\n",
    "                if gse in gse_cRNA:\n",
    "                    select_gse.append(gse)\n",
    "                    print(f\"{gse} selected\")\n",
    "                else:\n",
    "                    print(f\"{gse} not selected due to not target seq type\")\n",
    "    disease_select_gse_dict[disease] = select_gse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_select_gse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d871f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abundance_feature_union_set(selected_gse_list: list[str]):\n",
    "    abundance_t_dict: dict[str, pd.DataFrame] = {}\n",
    "    all_features = set()\n",
    "    for gse in selected_gse_list:\n",
    "        abundance_t = pd.read_excel(\n",
    "            Rf\"D:\\Project\\gutDBase\\bracken_summary_GSE_filtered\\{host}\\{gse.split('_')[0]}_summary.xlsx\", index_col=0, sheet_name=taxonomy).T\n",
    "        # abundance_t.columns = abundance_t.columns.str.replace(\n",
    "        #     R\"\\.\\d+$\", \"\", regex=True)\n",
    "        # abundance_t = abundance_t.groupby(abundance_t.columns, axis=1).mean()\n",
    "        abundance_t_dict[gse] = abundance_t\n",
    "        all_features.update(abundance_t.columns)\n",
    "\n",
    "    all_features = sorted(all_features, reverse=True)\n",
    "\n",
    "    new_abundance_t_dict = {}\n",
    "    for gse in selected_gse_list:\n",
    "        new_abundance_t = abundance_t_dict[gse].copy()\n",
    "        new_abundance_t = new_abundance_t.reindex(\n",
    "            columns=all_features, fill_value=0)\n",
    "        new_abundance_t_dict[gse] = new_abundance_t\n",
    "\n",
    "    return new_abundance_t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(selected_gse_list: list[str]):\n",
    "    label_dict: dict[str, pd.Series] = {}\n",
    "    for gse in selected_gse_list:\n",
    "        records = metadata[(metadata['info'] == 'metaclass')\n",
    "                           & (metadata['accession'] == gse)]\n",
    "        y = records[['sample', 'value']]\n",
    "        y = y.set_index('sample')['value'].map(\n",
    "            lambda x: 0 if x == 'normal' else 1)\n",
    "        label_dict[gse] = y\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb61248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_gse_x_y_dict(abundance_t_dict: dict[str, pd.DataFrame], label_dict: dict[str, pd.Series], selected_gse_list: list[str]):\n",
    "    gse2x_y_dict = {}\n",
    "    for gse in selected_gse_list:\n",
    "        x = abundance_t_dict[gse]\n",
    "        y = label_dict[gse]\n",
    "        shared_index = x.index.intersection(y.index)\n",
    "        x = x.loc[shared_index]\n",
    "        y = y.loc[shared_index]\n",
    "        # metadata deduplication\n",
    "        y = y[~y.index.duplicated(keep=\"first\")]\n",
    "        gse2x_y_dict[gse] = {\"x\": x, \"y\": y}\n",
    "    return gse2x_y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bab4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2_x_y_dict: dict[str, dict[str, pd.DataFrame | pd.Series]] = {}\n",
    "for disease, gse_list in disease_select_gse_dict.items():\n",
    "    if len(gse_list) < 2:\n",
    "        print(f\"{disease} insufficient quantity of fewer than 2, skipping.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{disease}: {len(gse_list)}\")\n",
    "        gse_abundance_t_dict = abundance_feature_union_set(gse_list)\n",
    "        gse_label_dict = extract_label(gse_list)\n",
    "        x_y_dict = composite_gse_x_y_dict(\n",
    "            gse_abundance_t_dict, gse_label_dict, gse_list)\n",
    "        gse2_x_y_dict[disease] = x_y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease, gse_x_y in gse2_x_y_dict.items():\n",
    "    for gse, x_y in gse_x_y.items():\n",
    "        print(f\"{disease}\\t{gse}\\t{x_y['x'].shape}\\t{x_y['y'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from debiasm import DebiasMClassifier\n",
    "\n",
    "\n",
    "def merge_and_add_batch_labels(gse_x_y_dict: dict[str, dict[str, pd.DataFrame | pd.Series]]):\n",
    "    \"\"\"\n",
    "    Merge multiple GSE datasets under a disease, with batch numbers in the first column.\n",
    "    Return X_all, y_all, batch_1abels\n",
    "    \"\"\"\n",
    "    X_list, y_list, batch_list = [], [], []\n",
    "    feature_names: list[str] = []\n",
    "    sample_names: list[str] = []\n",
    "    for batch_id, (gse, x_y) in enumerate(gse_x_y_dict.items()):\n",
    "        feature_names = x_y[\"x\"].columns.tolist()\n",
    "        sample_names.extend(x_y[\"x\"].index.tolist())\n",
    "        x = x_y[\"x\"].values\n",
    "        y = x_y[\"y\"].values\n",
    "\n",
    "        # Add batch number column before X\n",
    "        batch_col = np.full((x.shape[0], 1), batch_id)\n",
    "        x_with_batch = np.hstack((batch_col, x))\n",
    "\n",
    "        X_list.append(x_with_batch)\n",
    "        y_list.append(y)\n",
    "        batch_list.extend([gse]*x.shape[0])\n",
    "\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "\n",
    "    return X_all, y_all, batch_list, feature_names, sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_validation(X_all: np.ndarray, y_all: np.ndarray):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X_all: numpy array, shape (n_samples, n_features+1)，first column is batch_id\n",
    "        y_all: numpy array, shape (n_samples,)\n",
    "    output:\n",
    "        X_train, X_val, y_train, y_val\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that y_all is a numpy array\n",
    "    if not isinstance(y_all, np.ndarray):\n",
    "        y_all = y_all.to_numpy()\n",
    "\n",
    "    # Check if the sample size is aligned\n",
    "    assert X_all.shape[0] == y_all.shape[0], f\"Sample size mismatch: X={X_all.shape[0]}, y={y_all.shape[0]}\"\n",
    "\n",
    "    # Select the maximum batch_id as the validation set\n",
    "    batch_ids = X_all[:, 0].astype(int)\n",
    "    unique, counts = np.unique(batch_ids, return_counts=True)\n",
    "    most_common_batch = unique[counts.argmax()]   # The batch_id with the most occurrences\n",
    "    val_inds = (batch_ids == most_common_batch)\n",
    "\n",
    "    # split the data into training and validation sets\n",
    "    X_train, X_val = X_all[~val_inds], X_all[val_inds]\n",
    "    y_train, y_val = y_all[~val_inds], y_all[val_inds]\n",
    "\n",
    "    print(f\"total: {len(y_all)} | training set: {len(y_train)} | validation set: {len(y_val)} | unique batch_ids: {len(np.unique(batch_ids))}\")\n",
    "\n",
    "    # check if there are any NaN\n",
    "    print(\"X_train has NaN:\", np.isnan(X_train).any())\n",
    "    print(\"X_val has NaN:\", np.isnan(X_val).any())\n",
    "    print(\"y_train has NaN:\", pd.isnull(y_train).any())\n",
    "    print(\"y_val has NaN:\", pd.isnull(y_val).any())\n",
    "\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668dd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias_batch_analysis(X_train, X_val, y_train, y_val, X_all):\n",
    "\n",
    "    dmc = DebiasMClassifier(x_val=X_val)\n",
    "    dmc.fit(X_train, y_train)\n",
    "\n",
    "    X_debiassed = dmc.transform(X_all)\n",
    "    return X_debiassed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease2_debiased = {}\n",
    "\n",
    "for disease, gse_x_y in gse2_x_y_dict.items():\n",
    "    print(f\"Processing {disease}, with a total of {len (gse_x_y)} datasets\")\n",
    "    temp_gse, temp_x_y = next(iter(gse_x_y.items()))\n",
    "    # feature_names = temp_x_y['x'].columns.tolist()\n",
    "    # print(f\"There are {len (feature_name)} features in total\")\n",
    "    # sample_names = []\n",
    "    # for gse, x_y in gse_x_y.items():\n",
    "    #     gses = x_y['y'].index.tolist()\n",
    "    #     sample_names.extend(gses)\n",
    "    X_all, y_all, batch_labels, feature_names, sample_names = merge_and_add_batch_labels(gse_x_y)\n",
    "\n",
    "    print(\"has NaN:\", np.isnan(X_all).any())\n",
    "    print(\"NaN number:\", np.isnan(X_all).sum())\n",
    "\n",
    "    # If it is a DataFrame, you can check the specific location\n",
    "    if not isinstance(X_all, np.ndarray):\n",
    "        nan_locs = X_all.isnull().sum().sort_values(ascending=False)\n",
    "        print(\"The top 10 features with the most NaN:\")\n",
    "        print(nan_locs.head(10))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = split_training_validation(X_all, y_all)\n",
    "    X_debiassed = debias_batch_analysis(X_train, X_val, y_train, y_val, X_all)\n",
    "    X_debiassed = pd.DataFrame(\n",
    "        X_debiassed, columns=feature_names, index=sample_names)\n",
    "\n",
    "    sample_y_batch = pd.DataFrame(\n",
    "        {'y': y_all, 'batch': batch_labels}, index=sample_names)\n",
    "    sample_y_batch.index.name = 'Sample Name'\n",
    "\n",
    "    disease2_debiased[disease] = {\n",
    "        \"X_raw\": X_all,\n",
    "        \"X_debiassed\": X_debiassed,\n",
    "        \"sample_y_batch\": sample_y_batch\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e624a40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lefse_preprocess(disease: str)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    lefse preprocess\n",
    "    \"\"\"\n",
    "    # Calculate the composition of each sample\n",
    "    mat = disease2_debiased[disease]['X_debiassed'].copy()\n",
    "    mat_meta = disease2_debiased[disease]['sample_y_batch'].copy()\n",
    "    mat_meta.replace({'y': {1: disease, 0: 'normal'}}, inplace=True)\n",
    "    mat_meta['Sample Name'] = mat_meta.index\n",
    "    mat.insert(0, 'Group', mat_meta.loc[mat.index]['y'])\n",
    "    mat = mat.T\n",
    "    mat.index.name = 'Subject'\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease, abu_data in disease2_debiased.items():\n",
    "    mat = get_lefse_preprocess(disease)\n",
    "    mat.to_csv(Rf\"D:\\Project\\gutDBase\\debias\\{host}\\{disease}.tsv\",sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
